# 环境初始化

## 1 检查操作系统的版本

```powershell
# 此方式下安装kubernetes集群系统版本为：CentOS Stream release 8 版本号：4.18.0-408.el8.x86_64
[root@CentOS-K8S-Master ~]# cat /etc/redhat-release 
CentOS Stream release 8
[root@CentOS-K8S-Master ~]# uname -a
Linux CentOS-K8S-Master 4.18.0-408.el8.x86_64 #1 SMP Mon Jul 18 17:42:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux

```

## 2 主机名解析

为了方便集群节点间的直接调用，在这个配置一下主机名解析，企业中推荐使用内部DNS服务器

```powershell
修改主机名使用：hostnamectl set-hostname 主机名 

# 主机名成解析 编辑三台服务器的/etc/hosts文件，添加下面内容

cat >> /etc/hosts <<EOF
192.168.10.131  k8s-master01
192.168.10.141  k8s-node01
192.168.10.142  k8s-node02
EOF
```

## 3 时间同步

kubernetes要求集群中的节点时间必须精确一直，这里使用chronyd服务从网络同步时间

企业中建议配置内部的会见同步服务器

```powershell
# 启动chronyd服务
[root@master ~]# systemctl start chronyd
[root@master ~]# systemctl enable chronyd
[root@master ~]# date
```

## 4  禁用iptable和firewalld服务

kubernetes和docker 在运行的中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则

```powershell
# 1 关闭firewalld服务
[root@master ~]# systemctl stop firewalld
[root@master ~]# systemctl disable firewalld
# 2 关闭iptables服务
[root@master ~]# systemctl stop iptables
[root@master ~]# systemctl disable iptables
```

## 5 禁用selinux

selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题

```powershell
# 编辑 /etc/selinux/config 文件，修改SELINUX的值为disable
# 注意修改完毕之后需要重启linux服务
SELINUX=disabled

命令方式修改
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
```

## 6 禁用swap分区

swap分区指的是虚拟内存分区，它的作用是物理内存使用完，之后将磁盘空间虚拟成内存来使用，启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备，但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明

```powershell
方式一：重新启动电脑，永久禁用Swap
# 编辑分区配置文件/etc/fstab，注释掉swap分区一行
# 注意修改完毕之后需要重启linux服务
vim /etc/fstab
注释掉 /dev/mapper/centos-swap swap
# /dev/mapper/centos-swap swap

方式二：不重启电脑，禁用启用swap，立刻生效
swapoff -a 禁用命令
swapon -a  启用命令
free -mh   查看交换分区的状态:
```



## 7 修改linux的内核参数

管理员可以通过 sysctl 接口修改内核运行时的参数,在 `/proc/sys/` 虚拟文件系统下存放许多内核参数。这些参数涉及了多个内核子系统，如：

- 内核子系统（通常前缀为: `kernel.`）
- 网络子系统（通常前缀为: `net.`）
- 虚拟内存子系统（通常前缀为: `vm.`）

若要获取完整的参数列表，请执行以下命令：

```shell
sudo sysctl -a
```

* net.bridge.bridge-nf-call-iptables：开启桥设备内核监控（ipv4）
* net.ipv4.ip_forward：开启路由转发
* net.bridge.bridge-nf-call-ip6tables：开启桥设备内核监控（ipv6）



```shell
内核低于 4.1 版本需要添加 fs.may_detach_mounts=1 和 net.ipv4.tcp_tw_recycle=0

在内核低于 4.1 中，不要设置 net.ipv4.tcp_tw_recycle 这个参数为 1
，网上有不少教程没提到或者内核版本过低系统默认设置为 1
开启此参数，对于外网的 sockets 链接会快速回收。但是对于内网会导致大量的 TCP 链接建立错误。k8s
使用的都是在内网，所以要禁用！设置为 0
有关 net.ipv4.tcp_tw_recycle 参数查看文章(https://cloud.tencent.com/developer/article/1683704)

参数 fs.may_detach_mounts 则是跟容器相关的。该参数如果设置为 0，会导致服务变更后旧 pod
在回收时会一直卡在 Terminating 的状态，会重复出现 UnmountVolume.TearDown failed for volume 错误。
有关 fs.may_detach_mounts 参数产生的 bug 查看文章(https://github.com/kubernetes/kubernetes/issues/51835)
以及 (https://bugzilla.redhat.com/show_bug.cgi?id=1441737) 。
```

以上3项为必须参数，其他参数可根据需要添加

```powershell
# 修改linux的内核采纳数，添加网桥过滤和地址转发功能
# 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置：

cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# 设置所需的 sysctl 参数，参数在重新启动后保持不变

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# 应用 sysctl 参数而不重新启动
sudo sysctl --system

# 重新加载配置
[root@master ~]# sysctl -p
# 加载网桥过滤模块
[root@master ~]# modprobe br_netfilter
[root@master ~]# modprobe overlay
# 查看网桥过滤模块是否加载成功
[root@master ~]# lsmod | grep br_netfilter
[root@master ~]# lsmod | grep overlay
```

通过运行以下指令确认 `net.bridge.bridge-nf-call-iptables`、`net.bridge.bridge-nf-call-ip6tables` 和 `net.ipv4.ip_forward` 系统变量在你的 `sysctl` 配置中被设置为 1：

```bash
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

## 8 配置ipvs功能

在Kubernetes中Service有两种带来模型，一种是基于iptables的，一种是基于ipvs的两者比较的话，ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块

参考文档：https://kubernetes.io/zh-cn/blog/2018/07/09/ipvs-based-in-cluster-load-balancing-deep-dive/

服务代理：https://kubernetes.io/zh-cn/docs/reference/networking/virtual-ips/



Kubernetes（k8s）多主集群通常建议使用IPVS（IP Virtual Server）作为服务代理，原因主要包括以下几点：

（1）性能优势：

- IPVS内置于Linux内核中，其基于哈希表的快速查找机制在大规模高并发场景下比iptables（Netfilter）的NAT模式具有更高的性能和更低的延迟。

（2）负载均衡算法丰富：

-    IPVS支持丰富的负载均衡算法，包括轮询、最少连接、源哈希、加权轮询等，可以根据业务需求灵活选择合适的负载均衡策略。

（3）会话保持能力：

- IPVS支持多种会话保持方式，例如源IP地址会话保持、目的IP地址会话保持、TCP/UDP端口会话保持等，这对于保持客户端与后端服务之间的长连接或状态相关的应用至关重要。

（4）更好的可扩展性和稳定性：

- 在大规模集群中，随着Service数量的增长，iptables规则的数量也会迅速增加，这可能会影响系统的稳定性和性能。而IPVS则通过内核态实现高效的负载均衡和转发，避免了这个问题。

（5）更精细的服务管理：

- IPVS可以对单个服务进行粒度更细的管理，如单独设置服务的健康检查、权重调整等，更适合复杂的云原生环境。

（6）支持集群内部通信：

- 在k8s集群内部，kube-proxy组件利用IPVS可以更好地处理Pod间的通信和服务发现。

因此，在构建Kubernetes多主集群时，使用IPVS能够提供更高效率、更稳定的网络服务代理功能，以满足分布式系统中的高可用和高性能需求。不过，IPVS并不是必须选项，kube-proxy也支持iptables和userspace两种模式，但在大规模生产环境中，IPVS往往是首选方案。



IPVS (IP Virtual Server)用于实现传输层负载均衡。

```powershell
# 1.安装ipset和ipvsadm

[root@master ~]# yum install ipset ipvsadm -y

# 2.添加需要加载的模块写入脚本文件

[root@master ~]# cat <<EOF> /etc/sysconfig/modules/ipvs.modules
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4 
EOF

# 在内核4.19+版本nf_conntrack_ipv4已经改为nf_conntrack，

[root@master ~]# cat <<EOF> /etc/sysconfig/modules/ipvs.modules
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack （4.19+内核以下使用nf_conntrack）
EOF

# 3.为脚本添加执行权限
[root@master ~]# chmod +x /etc/sysconfig/modules/ipvs.modules
# 4.执行脚本文件
[root@master ~]# /bin/bash /etc/sysconfig/modules/ipvs.modules
# 5.查看对应的模块是否加载成功
[root@master ~]# lsmod | grep -e ip_vs -e nf_conntrack
低版本运行 ：
[root@master ~]# lsmod | grep -e ip_vs -e nf_conntrack_ipv4
```

## 9 设置系统时区与同步

设置时区

```shell
timedatectl set-timezone Asia/ShanghaiCOPY
```

同步时区

```shell
systemctl enable chronyd && \
systemctl start chronyd
```

查看

```shell
timedatectl status
```

*显示如下*

>
> `Time zone: Asia/Shanghai (CST, +0800)` 表示使用东八区时区
> `System clock synchronized: yes` 表示时区有同步
> `NTP service: active` 表示开启了时区同步服务

```text
               Local time: 三 2022-09-21 01:12:09 CST
           Universal time: 二 2022-09-20 17:12:09 UTC
                 RTC time: 二 2022-09-20 17:12:09
                Time zone: Asia/Shanghai (CST, +0800)
System clock synchronized: yes
              NTP service: active
          RTC in local TZ: no
```

将当前的 UTC 时间写入硬件时钟

```shell
timedatectl set-local-rtc 0
```

重启依赖于系统时间的服务

```shell
systemctl restart rsyslog && \
systemctl restart crond
```

## 10 设置 systemd journald

创建持久化保存日志的目录以及添加配置并生效

```shell
mkdir /var/log/journal && \
mkdir /etc/systemd/journald.conf.d && \
cat > /etc/systemd/journald.conf.d/99-prophet.conf <<EOF
[Journal]
# 持久化保存到磁盘
Storage=persistent
# 压缩历史日志
Compress=yes
SyncIntervalSec=5m
RateLimitInterval=30s
RateLimitBurst=1000
# 最大占用空间 10G
SystemMaxUse=10G
# 单日志文件最大 200M
SystemMaxFileSize=200M
# 日志保存时间 2 周
MaxRetentionSec=2week
# 不将日志转发到 syslog
ForwardToSyslog=no
EOF
systemctl restart systemd-journald
```

## 11 创建 k8s_init.lock

初始化后创建 `k8s_init.lock` 文件。

下次初始化查看是否有该文件，以免重复初始化造成意外问题。

```shell
touch /tmp/k8s_init.lock
```

**重启**

```shell
shutdown -r now
```
